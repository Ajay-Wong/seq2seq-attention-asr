{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'Attention';\n",
    "require 'LSTM';\n",
    "require 'nngraph';\n",
    "require 'RNN';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 4\n",
    "seqLength = 24\n",
    "inputFrameSize = 10\n",
    "outputFrameSize = 5\n",
    "kW = 5\n",
    "\n",
    "enc_inp = nn.Identity()()\n",
    "\n",
    "convlayer = nn.Sequential()\n",
    "convlayer:add(nn.TemporalConvolution(inputFrameSize,outputFrameSize,kW))\n",
    "convlayer:add(nn.ReLU())\n",
    "convlayer:add(nn.TemporalMaxPooling(2,2))\n",
    "L = (seqLength - kW + 1)/2\n",
    "\n",
    "fRNN = nn.RNN(nn.LSTM(outputFrameSize,outputFrameSize,False),L,false)(convlayer(enc_inp))\n",
    "bRNN = nn.RNN(nn.LSTM(outputFrameSize,outputFrameSize,False),L,true)(convlayer(enc_inp))\n",
    "\n",
    "concat = nn.JoinTable(2,2)({fRNN,bRNN})\n",
    "\n",
    "encoder = nn.gModule({enc_inp},{concat})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = torch.randn(seqLength,inputFrameSize)\n",
    "enc_out  = encoder:forward(inp)\n",
    "enc_grad = encoder:backward(inp,torch.ones(L,outputFrameSize*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = torch.randn(batchSize,seqLength,inputFrameSize)\n",
    "enc_out  = encoder:forward(inp)\n",
    "enc_grad = encoder:backward(inp,torch.ones(batchSize,L,outputFrameSize*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreDepth = 5\n",
    "hybridAttendFilterSize = 3\n",
    "hybridAttendFeatureMaps = 4\n",
    "stateDepth = 4\n",
    "annotationDepth = outputFrameSize*2\n",
    "outputDepth = 2\n",
    "--L = 10\n",
    "T = 9\n",
    "peepholes = false\n",
    "mlpDepth = 7\n",
    "\n",
    "\n",
    "decoder_recurrent = nn.LSTM(stateDepth,stateDepth,peepholes)\n",
    "\n",
    "------------------ decoder_mlp ------------------\n",
    "-- inputs:\n",
    "--   s_t       ~ input      ~ stateDepth\n",
    "--   c_t       ~ input      ~ annotationDepth\n",
    "-- outputs:\n",
    "--   y_t       ~ output     ~ outputDepth\n",
    "dec_mlp_inp = nn.Identity()()\n",
    "mlp_inp = nn.JoinTable(1,1)(dec_mlp_inp)\n",
    "mlp     = nn.Sequential()\n",
    "mlp:add(nn.Linear(stateDepth+annotationDepth,mlpDepth))\n",
    "mlp:add(nn.ReLU())\n",
    "mlp:add(nn.Linear(mlpDepth,outputDepth))\n",
    "mlp:add(nn.LogSoftMax())\n",
    "decoder_mlp = nn.gModule({dec_mlp_inp},{mlp(mlp_inp)})\n",
    "\n",
    "\n",
    "decoder = nn.Attention(decoder_recurrent,decoder_mlp,scoreDepth,hybridAttendFilterSize,hybridAttendFeatureMaps,stateDepth,annotationDepth,outputDepth,L,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = torch.ones(L,annotationDepth)\n",
    "decoder:forward(h)\n",
    "decoder:backward(h,torch.ones(T,outputDepth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = torch.ones(batchSize,L,annotationDepth)\n",
    "decoder:forward(h)\n",
    "decoder:backward(h,torch.ones(batchSize,T,outputDepth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder - Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoenc_inp = nn.Identity()()\n",
    "autoencoder = nn.gModule({autoenc_inp},{decoder(encoder(autoenc_inp))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       "[torch.DoubleTensor of size 9]\n",
       "\n",
       " 0  1\n",
       " 1  0\n",
       " 0  1\n",
       " 0  1\n",
       " 1  0\n",
       " 0  1\n",
       " 1  0\n",
       " 0  1\n",
       " 0  1\n",
       "[torch.DoubleTensor of size 9x2]\n",
       "\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.ceil(torch.rand(T)*outputDepth)\n",
    "print(target)\n",
    "print(torch.zeros(T,outputDepth):scatter(2,target:reshape(T,1):long(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2  2  1  1  1  2  2  1  1\n",
       " 2  1  1  1  2  1  2  2  2\n",
       " 2  1  1  1  2  2  2  2  1\n",
       " 1  2  2  1  1  1  1  1  2\n",
       "[torch.DoubleTensor of size 4x9]\n",
       "\n",
       "(1,.,.) = \n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "\n",
       "(2,.,.) = \n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "\n",
       "(3,.,.) = \n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "\n",
       "(4,.,.) = \n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "[torch.DoubleTensor of size 4x9x2]\n",
       "\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.ceil(torch.rand(batchSize,T)*outputDepth)\n",
    "print(target)\n",
    "print(torch.zeros(batchSize,T,outputDepth):scatter(3,target:reshape(batchSize,T,1):long(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my nll 6.0380990025673\t\n",
       "nn nll 6.0380990025673\t\n",
       "0\t\n",
       " 9\n",
       " 2\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(seqLength,inputFrameSize)\n",
    "target = torch.ceil(torch.rand(T)*outputDepth)\n",
    "autoenc_out  = autoencoder:forward(inp)\n",
    "labelmask = torch.zeros(T,outputDepth):scatter(2,target:reshape(T,1):long(),1)\n",
    "nll = -torch.cmul(autoenc_out,labelmask)\n",
    "print('my nll ' .. nll:sum())\n",
    "\n",
    "nll = 0\n",
    "for t=1,T do\n",
    "    nll = nn.ClassNLLCriterion():forward(autoenc_out[t],target[t]) + nll\n",
    "end\n",
    "print('nn nll ' .. nll)\n",
    "\n",
    "crit_grad1 = -labelmask\n",
    "crit_grad2 = nn.ClassNLLCriterion():backward(autoenc_out,target)\n",
    "print((crit_grad1-crit_grad2):norm())\n",
    "\n",
    "autoenc_grad = autoencoder:backward(inp,torch.ones(L,outputDepth))\n",
    "print(autoenc_out:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my nll 6.2530219316573\t\n",
       "nn nll 6.2530219316573\t\n",
       " 4\n",
       " 9\n",
       " 2\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(batchSize,seqLength,inputFrameSize)\n",
    "\n",
    "target = torch.ceil(torch.rand(batchSize,T)*outputDepth)\n",
    "labelmask = torch.zeros(batchSize,T,outputDepth):scatter(3,target:reshape(batchSize,T,1):long(),1)\n",
    "\n",
    "autoenc_out  = autoencoder:forward(inp)\n",
    "\n",
    "nll = -torch.cmul(labelmask,autoenc_out)/batchSize\n",
    "print('my nll ' .. nll:sum())\n",
    "\n",
    "nll = 0\n",
    "for b=1,batchSize do\n",
    "    for t=1,T do\n",
    "        nll = nn.ClassNLLCriterion():forward(autoenc_out[{b,t}],target[{b,t}]) + nll\n",
    "    end\n",
    "end\n",
    "print('nn nll ' .. nll/batchSize)\n",
    "\n",
    "crit_grad1 = -labelmask/batchSize\n",
    "\n",
    "autoenc_grad = autoencoder:backward(inp,crit_grad1)\n",
    "print(autoenc_out:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 9\n",
       " 2\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc_out:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 9\n",
       " 2\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(batchSize,T,outputDepth):size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.LongTensor\t\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target:reshape(batchSize,T,1):long():type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, pred = autoenc_out:max(3)\n",
    "pred = pred:squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 9\n",
       " 1\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  1  0  1  0  1  1  0  0\n",
       " 0  1  0  1  1  1  1  1  1\n",
       " 0  0  0  0  0  0  1  0  1\n",
       " 0  1  0  0  1  1  0  1  1\n",
       "[torch.ByteTensor of size 4x9]\n",
       "\n"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(pred:double(),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  0  2\n",
       "  1  0\n",
       "  0  2\n",
       "  1  0\n",
       "  0  2\n",
       "  1  0\n",
       "  1  0\n",
       "  0  2\n",
       "  0  2\n",
       "\n",
       "(2,.,.) = \n",
       "  0  2\n",
       "  1  0\n",
       "  0  2\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "\n",
       "(3,.,.) = \n",
       "  0  2\n",
       "  0  2\n",
       "  0  2\n",
       "  0  2\n",
       "  0  2\n",
       "  0  2\n",
       "  1  0\n",
       "  0  2\n",
       "  1  0\n",
       "\n",
       "(4,.,.) = \n",
       "  0  2\n",
       "  1  0\n",
       "  0  2\n",
       "  0  2\n",
       "  1  0\n",
       "  1  0\n",
       "  0  2\n",
       "  1  0\n",
       "  1  0\n",
       "[torch.DoubleTensor of size 4x9x2]\n",
       "\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(target:size(1),T,outputDepth):scatter(3,target:view(target:size(1),T,1):long(),target:view(target:size(1),T,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 9\n",
       " 1\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target:view(target:size(1),T,1):long():size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training time  =\t0.6 minutes\t\n"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('training time  =', torch.round(10*(sys.clock()-start)/60)/10 .. ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "\n",
       "(2,.,.) = \n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "  1  0\n",
       "\n",
       "(3,.,.) = \n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "\n",
       "(4,.,.) = \n",
       "  0  1\n",
       "  1  0\n",
       "  0  1\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "  0  1\n",
       "  1  0\n",
       "  1  0\n",
       "[torch.DoubleTensor of size 4x9x2]\n",
       "\n"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(batchSize,T,outputDepth):scatter(3,target:reshape(batchSize,T,1):long(),torch.ones(batchSize,T,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 9\n",
       " 1\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target:reshape(batchSize,T,1):size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "\n",
       "(2,.,.) = \n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "\n",
       "(3,.,.) = \n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "\n",
       "(4,.,.) = \n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "[torch.DoubleTensor of size 4x9x1]\n",
       "\n"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(batchSize,T,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
